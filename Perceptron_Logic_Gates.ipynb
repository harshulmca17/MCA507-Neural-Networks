{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron-Logic-Gates.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayant-dhawan/MCA507-Neural-Networks/blob/master/Perceptron_Logic_Gates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmKhMNO_nRQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4U7A23kny-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron(object):\n",
        "  def __init__(self, inputs = 2, weights = [1,1], bias = 2):\n",
        "    if(inputs != len(weights)):\n",
        "      print(\"Error\")\n",
        "      exit\n",
        "    self.inputs = inputs\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def activateNeuron(self, input):\n",
        "    \"\"\"\n",
        "    Activate neuron for a input combination and output the result for the input.\n",
        "    g(x) for the input is calclulated means the sum of the inputs.\n",
        "    \"\"\"\n",
        "    sumOfInputs = numpy.inner(input, self.weights) # Calculating sum of all the inputs*weights.\n",
        "    if sumOfInputs - bias >= 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  \n",
        "  def drawOutput(self):\n",
        "    \"\"\"\n",
        "    Returns a table which has output for all the combinations of the input.\n",
        "    \"\"\"\n",
        "    combinations = numpy.array([list(i) for i in itertools.product([0, 1], repeat=self.inputs)]) # Finding all the combinations for the given number of inputs.\n",
        "    inputLabels = [\"x\" + str(i) for i in range(1, self.inputs+1)]\n",
        "    outputTable = pandas.DataFrame(combinations, columns = inputLabels)\n",
        "    outputLabel = \"y\"\n",
        "    outputValue = []\n",
        "    for combination in combinations:\n",
        "      outputValue.append(self.activateNeuron(combination)) # Firirng perceptron for every combination of the input.\n",
        "      outputTable[outputLabel] = pandas.Series(outputValue)\n",
        "    return outputTable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKdZp0RmqdNU",
        "colab_type": "text"
      },
      "source": [
        "# Working\n",
        "\n",
        "**Inputs:**\n",
        "\n",
        "\n",
        "*   No of inputs (inputs): Number of inputs for the logic gates.\n",
        "*   Weights (weights): Weight of every input corresponding to the input.\n",
        "*   Bias (bias): Threshold for the inputs.\n",
        "\n",
        "\n",
        "Weighted sum of every input combination is calculated and if the diffrence between sum of weighted inputs to the bias is greater than 0 it will ouput 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZCxBL-dpM1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "717c179a-fe18-4a8e-dac4-4f22ccc3d2de"
      },
      "source": [
        "# AND Gate\n",
        "inputs = 2; \n",
        "weights = [0.5, 0.5]\n",
        "bias = 1\n",
        "print(Perceptron(inputs, weights, bias).drawOutput())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  0\n",
            "1   0   1  0\n",
            "2   1   0  0\n",
            "3   1   1  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIxWOBFvpk0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "45cb2f7f-9a31-4d93-9bff-1a1219014c64"
      },
      "source": [
        "# OR Gate\n",
        "inputs = 2; \n",
        "weights = [1, 1]\n",
        "bias = 1\n",
        "print(Perceptron(inputs, weights, bias).drawOutput())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  0\n",
            "1   0   1  1\n",
            "2   1   0  1\n",
            "3   1   1  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iwfSAXXp3P9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "93bade43-fb21-46f5-9ac1-cb3dddc5b3d8"
      },
      "source": [
        "# NOT Gate\n",
        "inputs = 1; \n",
        "weights = [-1]\n",
        "bias = 0\n",
        "print(Perceptron(inputs, weights, bias).drawOutput())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  y\n",
            "0   0  1\n",
            "1   1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny2QhlNNqAYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "1b35cd69-8857-4887-8198-c62b080823d1"
      },
      "source": [
        "# NAND Gate\n",
        "inputs = 2; \n",
        "weights = [-1, -1]\n",
        "bias = -1\n",
        "print(Perceptron(inputs, weights, bias).drawOutput())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  1\n",
            "1   0   1  1\n",
            "2   1   0  1\n",
            "3   1   1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQIcHF0_qGnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "0ae62e94-804f-485e-e673-1ad0b256ad34"
      },
      "source": [
        "# NOR Gate\n",
        "inputs = 2; \n",
        "weights = [-1, -1]\n",
        "bias = -0.5\n",
        "print(Perceptron(inputs, weights, bias).drawOutput())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   x1  x2  y\n",
            "0   0   0  1\n",
            "1   0   1  0\n",
            "2   1   0  0\n",
            "3   1   1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_KOcYzTtI7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XOR gate and XNOR gate\n",
        "\"\"\"\n",
        "    XOR and XNOR gates can't be implemented by SINGLE preceptron\n",
        "    because it is not linearly separable\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}